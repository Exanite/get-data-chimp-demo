
[demo]

viewport.x = 54.24848445742532
viewport.y = 65.37782476809684
viewport.zoom = 0.6820739174396773

[[demo.nodes]]

width = 200.0
height = 265.0
position.x = 0.0
position.y = 0.0
id = 'get_data'
type = 'task'
data.name = 'get_data'
data.path = 'prep/workflow.py'
data.source = "df = pd.read_csv('https://raw.githubusercontent.com/getdatachimp/demo/main/prep/borked_iris.csv')\ndf"
data.nbSource = "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\ndf = pd.read_csv('https://raw.githubusercontent.com/getdatachimp/demo/main/prep/borked_iris.csv')\ndf\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\ny = df['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\npipeline = make_pipeline(\n  StandardScaler(),\n  LogisticRegression()\n)\n\nmodel = pipeline.fit(X_train, y_train)\nmodel.score(X_test, y_test)\nfrom doubtlab.ensemble import DoubtEnsemble\nfrom doubtlab.reason import ProbaReason, WrongPredictionReason\nreasons = {\n    'proba': ProbaReason(model=model),\n    'wrong_pred': WrongPredictionReason(model=model)\n}\n\n# Pass these reasons to a doubtlab instance.\ndoubt = DoubtEnsemble(**reasons)\n\n# Get the ordered indices of examples worth checking again\nindices = doubt.get_indices(X_train, y_train)\n# Get dataframe with \"reason\"-ing behind the sorting\npredicates = doubt.get_predicates(X_train, y_train)\ndf = df.join(predicates).drop(['Unnamed: 0'], axis=1)\ndf.iloc[predicates.index].head(len(indices))\nimport seaborn as sns\nsns.pairplot(data=df, hue='collector')\n# Use pandera to create simple check that features >= some values\nimport pandera as pa\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].max() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\nschema.validate(df)\n\ndf.loc[df['collector'] == 'Eric', 'petal_length'] /= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] /= 100\nschema.validate(df)\n# If there's time, use pandera for hypothesis testing check for something more robust\n#Here's what you can type into default.ipynb\nimport pandera as pa\nfrom pandera.errors import SchemaError\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].min() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\ndef validate():\n  try:\n    schema.validate(df)\n    return None\n  except SchemaError as ex:\n    return ex.failure_cases\nvalidate()\ndf.loc[df['collector'] == 'Eric', 'petal_length'] *= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] *= 100\ndf\n# Deploy pipeline to civo\n# If there's time, show cleanlab demo"
positionAbsolute.x = 0.0
positionAbsolute.y = 0.0

[[demo.nodes]]

width = 200.0
height = 265.0
position.x = 0.0
position.y = 300.0
id = 'prep'
type = 'task'
data.name = 'prep'
data.path = 'prep/workflow.py'
data.source = "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\ny = df['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
data.nbSource = "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\ndf = pd.read_csv('https://raw.githubusercontent.com/getdatachimp/demo/main/prep/borked_iris.csv')\ndf\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\ny = df['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\npipeline = make_pipeline(\n  StandardScaler(),\n  LogisticRegression()\n)\n\nmodel = pipeline.fit(X_train, y_train)\nmodel.score(X_test, y_test)\nfrom doubtlab.ensemble import DoubtEnsemble\nfrom doubtlab.reason import ProbaReason, WrongPredictionReason\nreasons = {\n    'proba': ProbaReason(model=model),\n    'wrong_pred': WrongPredictionReason(model=model)\n}\n\n# Pass these reasons to a doubtlab instance.\ndoubt = DoubtEnsemble(**reasons)\n\n# Get the ordered indices of examples worth checking again\nindices = doubt.get_indices(X_train, y_train)\n# Get dataframe with \"reason\"-ing behind the sorting\npredicates = doubt.get_predicates(X_train, y_train)\ndf = df.join(predicates).drop(['Unnamed: 0'], axis=1)\ndf.iloc[predicates.index].head(len(indices))\nimport seaborn as sns\nsns.pairplot(data=df, hue='collector')\n# Use pandera to create simple check that features >= some values\nimport pandera as pa\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].max() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\nschema.validate(df)\n\ndf.loc[df['collector'] == 'Eric', 'petal_length'] /= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] /= 100\nschema.validate(df)\n# If there's time, use pandera for hypothesis testing check for something more robust\n#Here's what you can type into default.ipynb\nimport pandera as pa\nfrom pandera.errors import SchemaError\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].min() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\ndef validate():\n  try:\n    schema.validate(df)\n    return None\n  except SchemaError as ex:\n    return ex.failure_cases\nvalidate()\ndf.loc[df['collector'] == 'Eric', 'petal_length'] *= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] *= 100\ndf\n# Deploy pipeline to civo\n# If there's time, show cleanlab demo"
positionAbsolute.x = 0.0
positionAbsolute.y = 300.0

[[demo.nodes]]

width = 200.0
height = 265.0
position.x = 0.0
position.y = 600.0
id = 'train'
type = 'task'
data.name = 'train'
data.path = 'prep/workflow.py'
data.source = "pipeline = make_pipeline(\n  StandardScaler(),\n  LogisticRegression()\n)\n\nmodel = pipeline.fit(X_train, y_train)"
data.nbSource = "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\ndf = pd.read_csv('https://raw.githubusercontent.com/getdatachimp/demo/main/prep/borked_iris.csv')\ndf\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\ny = df['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\npipeline = make_pipeline(\n  StandardScaler(),\n  LogisticRegression()\n)\n\nmodel = pipeline.fit(X_train, y_train)\nmodel.score(X_test, y_test)\nfrom doubtlab.ensemble import DoubtEnsemble\nfrom doubtlab.reason import ProbaReason, WrongPredictionReason\nreasons = {\n    'proba': ProbaReason(model=model),\n    'wrong_pred': WrongPredictionReason(model=model)\n}\n\n# Pass these reasons to a doubtlab instance.\ndoubt = DoubtEnsemble(**reasons)\n\n# Get the ordered indices of examples worth checking again\nindices = doubt.get_indices(X_train, y_train)\n# Get dataframe with \"reason\"-ing behind the sorting\npredicates = doubt.get_predicates(X_train, y_train)\ndf = df.join(predicates).drop(['Unnamed: 0'], axis=1)\ndf.iloc[predicates.index].head(len(indices))\nimport seaborn as sns\nsns.pairplot(data=df, hue='collector')\n# Use pandera to create simple check that features >= some values\nimport pandera as pa\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].max() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\nschema.validate(df)\n\ndf.loc[df['collector'] == 'Eric', 'petal_length'] /= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] /= 100\nschema.validate(df)\n# If there's time, use pandera for hypothesis testing check for something more robust\n#Here's what you can type into default.ipynb\nimport pandera as pa\nfrom pandera.errors import SchemaError\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].min() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\ndef validate():\n  try:\n    schema.validate(df)\n    return None\n  except SchemaError as ex:\n    return ex.failure_cases\nvalidate()\ndf.loc[df['collector'] == 'Eric', 'petal_length'] *= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] *= 100\ndf\n# Deploy pipeline to civo\n# If there's time, show cleanlab demo"
positionAbsolute.x = 0.0
positionAbsolute.y = 600.0

[[demo.nodes]]

width = 200.0
height = 265.0
position.x = 0.0
position.y = 900.0
id = 'score'
type = 'task'
data.name = 'score'
data.path = 'prep/workflow.py'
data.source = 'model.score(X_test, y_test)'
data.nbSource = "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\ndf = pd.read_csv('https://raw.githubusercontent.com/getdatachimp/demo/main/prep/borked_iris.csv')\ndf\nX = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\ny = df['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\npipeline = make_pipeline(\n  StandardScaler(),\n  LogisticRegression()\n)\n\nmodel = pipeline.fit(X_train, y_train)\nmodel.score(X_test, y_test)\nfrom doubtlab.ensemble import DoubtEnsemble\nfrom doubtlab.reason import ProbaReason, WrongPredictionReason\nreasons = {\n    'proba': ProbaReason(model=model),\n    'wrong_pred': WrongPredictionReason(model=model)\n}\n\n# Pass these reasons to a doubtlab instance.\ndoubt = DoubtEnsemble(**reasons)\n\n# Get the ordered indices of examples worth checking again\nindices = doubt.get_indices(X_train, y_train)\n# Get dataframe with \"reason\"-ing behind the sorting\npredicates = doubt.get_predicates(X_train, y_train)\ndf = df.join(predicates).drop(['Unnamed: 0'], axis=1)\ndf.iloc[predicates.index].head(len(indices))\nimport seaborn as sns\nsns.pairplot(data=df, hue='collector')\n# Use pandera to create simple check that features >= some values\nimport pandera as pa\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].max() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\nschema.validate(df)\n\ndf.loc[df['collector'] == 'Eric', 'petal_length'] /= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] /= 100\nschema.validate(df)\n# If there's time, use pandera for hypothesis testing check for something more robust\n#Here's what you can type into default.ipynb\nimport pandera as pa\nfrom pandera.errors import SchemaError\n\nschema = pa.DataFrameSchema({\n  'variety': pa.Column(str),\n  'petal_length': pa.Column(float, [\n    pa.Check(lambda g: g['Versicolor'].min() <= 30, groupby='variety'), \n    pa.Check(lambda g: g['Setosa'] <= 10, groupby='variety'),\n    pa.Check(lambda g: g['Virginica'] <= 40, groupby='variety')\n    ])\n})\n\ndef validate():\n  try:\n    schema.validate(df)\n    return None\n  except SchemaError as ex:\n    return ex.failure_cases\nvalidate()\ndf.loc[df['collector'] == 'Eric', 'petal_length'] *= 100\ndf.loc[df['collector'] == 'Eric', 'petal_width'] *= 100\ndf\n# Deploy pipeline to civo\n# If there's time, show cleanlab demo"
positionAbsolute.x = 0.0
positionAbsolute.y = 900.0

[[demo.edges]]

source = 'get_data'
target = 'prep'
markerEnd = 'arrowclosed'
id = 'reactflow__edge-get_data-prep'

[[demo.edges]]

source = 'prep'
target = 'train'
markerEnd = 'arrowclosed'
id = 'reactflow__edge-prep-train'

[[demo.edges]]

source = 'train'
target = 'score'
markerEnd = 'arrowclosed'
id = 'reactflow__edge-train-score'
